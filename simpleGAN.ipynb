{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,input_features):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(input_features,256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256,128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,z_dim,img_dim):\n",
    "        super(Generator,self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim,256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256,img_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.gen(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#HyperParameters\n",
    "lr=3e-4\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_epochs=100\n",
    "batch_size=32\n",
    "z_dim=64\n",
    "img_dim=784\n",
    "disc=Discriminator(img_dim).to(device)\n",
    "gen=Generator(z_dim,img_dim).to(device)\n",
    "optim_disc=optim.Adam(disc.parameters(),lr=lr)\n",
    "optim_gen=optim.Adam(gen.parameters(),lr=lr)\n",
    "criterion=nn.BCELoss()\n",
    "fixedNoise=torch.randn(batch_size,z_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "myTransforms=transforms.Compose(\n",
    "    [transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,))]\n",
    ")\n",
    "dataset=datasets.MNIST(root='./data',transform=myTransforms,download=True)\n",
    "loader=DataLoader(dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(dataset.train_data[0].shape)\n",
    "img=dataset.train_data[0]\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over loader to check if tensor created in (batch,img_dim)\n",
    "it=iter(loader)\n",
    "first,label=next(it)\n",
    "first.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 0/100 |Batch: 0/1875 | Gen Loss 0.6659 \n",
      "Epochs 1/100 |Batch: 0/1875 | Gen Loss 0.0000 \n",
      "Epochs 2/100 |Batch: 0/1875 | Gen Loss 0.0000 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m discLoss\u001b[38;5;241m=\u001b[39m(disc_fake_loss\u001b[38;5;241m+\u001b[39mdisc_real_loss)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     18\u001b[0m disc\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mdiscLoss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optim_disc\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# optim_disc.zero_grad()\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Generator Loss ---> log(1-d(g(z)))\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "for epochs in range(num_epochs):\n",
    "    for idx,(real_img,_) in enumerate(loader):\n",
    "        real_img=real_img.view(-1,784).to(device)\n",
    "        batch_size=real_img.shape[0]\n",
    "        noise=torch.randn(batch_size,z_dim).to(device)\n",
    "        fake_img=gen(noise)\n",
    "        disc_real=disc(real_img)\n",
    "        disc_fake=disc(fake_img)\n",
    "\n",
    "\n",
    "        #Discrimintor Loss ---> log(d(x))+log(1-d(g(z)))\n",
    "        disc_fake_loss=criterion(disc_fake,torch.ones_like(disc_fake))\n",
    "        disc_real_loss=criterion(disc_real,torch.ones_like(disc_real))\n",
    "\n",
    "        discLoss=(disc_fake_loss+disc_real_loss)/2\n",
    "        disc.zero_grad()\n",
    "        discLoss.backward(retain_graph=True)\n",
    "        optim_disc.step()\n",
    "        # optim_disc.zero_grad()\n",
    "\n",
    "        # Generator Loss ---> log(1-d(g(z)))\n",
    "\n",
    "        output=disc(fake_img)\n",
    "        genLoss=criterion(output,torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        genLoss.backward()\n",
    "        optim_gen.step()\n",
    "\n",
    "        if idx == 0:\n",
    "            print(f'Epochs {epochs}/{num_epochs} |Batch: {idx}/{len(loader)} | Gen Loss {genLoss:.4f} ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 784])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=gen(fixedNoise)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "noise=torch.randn(28,28)\n",
    "plt.imshow(noise,cmap='grey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
