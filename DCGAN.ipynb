{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialWeights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m ,(nn.Conv2d,nn.ConvTranspose2d,nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data,0.0,0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,z_dim,img_channels,features_g):\n",
    "        super(Generator,self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            self._block(z_dim,features_g*16,4,1,0),\n",
    "            self._block(features_g*16,features_g*8,4,2,1),\n",
    "            self._block(features_g*8,features_g*4,4,2,1),\n",
    "            self._block(features_g*4,features_g*2,4,2,1),\n",
    "            nn.ConvTranspose2d(features_g*2,img_channels,4,2,1),\n",
    "            nn.Tanh()\n",
    "\n",
    "        )\n",
    "    def _block(self,in_channels,out_channels,kernel_size,stride,padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels,out_channels,kernel_size,stride,padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,img_channels,features_d):\n",
    "        super().__init__()\n",
    "        self.disc=nn.Sequential(\n",
    "            nn.Conv2d(img_channels,features_d,kernel_size=4,stride=2,padding=1),\n",
    "            self._block(features_d,features_d*2,4,2,1),\n",
    "            self._block(features_d*2,features_d*4,4,2,1),\n",
    "            self._block(features_d*4,features_d*8,4,2,1),\n",
    "            nn.Conv2d(features_d*8,1,kernel_size=4,stride=2,padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def _block(self,in_channels,out_channels,kernel_size,stride,padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.02)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    N,in_channels,H,W=8,3,64,64\n",
    "    z_dim=100\n",
    "    x=torch.randn((N,in_channels,H,W))\n",
    "    disc=Discriminator(in_channels,8)\n",
    "    initialWeights(disc)\n",
    "    assert disc(x).shape==(N,1,1,1)\n",
    "\n",
    "    gen=Generator(z_dim,in_channels,8)\n",
    "    initialWeights(gen)\n",
    "    z=torch.randn((N,z_dim,1,1))\n",
    "    assert gen(z).shape== (N,in_channels, H, W)\n",
    "    \n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr=2e-4\n",
    "batch_size=128\n",
    "img_size=64\n",
    "in_channels=1\n",
    "z_dim=100\n",
    "num_epochs=5\n",
    "features_d=64\n",
    "features_g=64\n",
    "\n",
    "transforms=transforms.Compose(\n",
    "    [   \n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.5,),(0.5,)) #for single channel it works fine\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(in_channels)],[0.5 for _ in range(in_channels)]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset=datasets.MNIST(root='./data',train=True,transform=transforms,download=True)\n",
    "dataloader=DataLoader(dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torchvision/datasets/mnist.py:76: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "res=dataset.train_data[0]\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(res,cmap=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 64, 64])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it=iter(dataloader)\n",
    "first=next(it)\n",
    "img,target=first\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "disc=Discriminator(in_channels,features_d).to(device)\n",
    "initialWeights(disc)\n",
    "gen=Generator(z_dim,in_channels,features_g).to(device)\n",
    "initialWeights(gen)\n",
    "optim_disc=optim.Adam(gen.parameters(),lr=lr,betas=(0.5,0.999))\n",
    "optim_gen=optim.Adam(gen.parameters(),lr=lr,betas=(0.5,0.999))\n",
    "\n",
    "fixedNoise=torch.randn((batch_size,z_dim,1,1)).to(device)\n",
    "\n",
    "criterion=nn.BCELoss()\n",
    "# real_writer=SummaryWriter('/logs/real')\n",
    "# fake_writer=SummaryWriter('/logs/fake')\n",
    "# step=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/autograd/graph.py:825: UserWarning: Error detected in ConvolutionBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/cc/9wx87yxd1l1g7q88nc0g_tg00000gn/T/ipykernel_19949/2057641792.py\", line 6, in <module>\n",
      "    fake=gen(noise)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/var/folders/cc/9wx87yxd1l1g7q88nc0g_tg00000gn/T/ipykernel_19949/2810958259.py\", line 21, in forward\n",
      "    return self.net(x)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/shreygarg/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 1162, in forward\n",
      "    return F.conv_transpose2d(\n",
      " (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:115.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [128, 1, 4, 4]] is at version 6; expected version 5 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m lossG\u001b[38;5;241m=\u001b[39mcriterion(output,torch\u001b[38;5;241m.\u001b[39mones_like(output))\n\u001b[1;32m     23\u001b[0m gen\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m \u001b[43mlossG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m optim_gen\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLPytorch/myenv/lib/python3.9/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [128, 1, 4, 4]] is at version 6; expected version 5 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "for epochs in range(num_epochs):\n",
    "    for batch_idx,(real,target) in enumerate(dataloader):\n",
    "\n",
    "        real=real.to(device)\n",
    "        noise=torch.randn(batch_size,z_dim,1,1).to(device)\n",
    "        fake=gen(noise)\n",
    "\n",
    "        disc_real=disc(real).reshape(-1)\n",
    "        disc_real_loss=criterion(disc_real,torch.ones_like(disc_real))\n",
    "        disc_fake=disc(fake).reshape(-1)\n",
    "        \n",
    "        disc_fake_loss=criterion(disc_fake,torch.zeros_like(disc_fake))\n",
    "        \n",
    "        lossD=(disc_fake_loss+disc_real_loss)/2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        # lossD.backward()\n",
    "        optim_disc.step()\n",
    "\n",
    "\n",
    "        output=disc(fake).reshape(-1)\n",
    "        lossG=criterion(output,torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        optim_gen.step()\n",
    "\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(f'Epochs : {epochs}/{num_epochs} | Batch: {batch_idx}/{batch_size} | loss: {lossG:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
